# -*- coding: utf-8 -*-
"""EDA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JUbUL4x7ikWlhF6MYY_i-agRl8QwbZOg
"""

!pip install -q snownlp

import re
from pathlib import Path
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from tqdm.auto import tqdm
from snownlp import SnowNLP

# ------------------
# Parameters
# ------------------
INPUT_XLSX   = "Newspapers_merged_sorted.xlsx"
OUT_XLSX     = "EDA_and_basic_sentiment.xlsx"
SHE_REGEX    = r"(她)"   # subset: titles that explicitly contain "她..."
NEUTRAL_BAND = 0.05               # neutral band around 0.5 for labeling
TOP_N_PAPERS = 20                 # top-N newspapers by count to display

# ------------------
# Load data
# ------------------
df = pd.read_excel(INPUT_XLSX)
if "Title" not in df.columns:
    raise ValueError("Column `Title` not found in the input Excel file.")

df["Title"] = df["Title"].astype(str).str.strip()
# Derive year from Time if present (coerce errors to NaT)
df["year"]  = pd.to_datetime(df.get("Time"), errors="coerce").dt.year

# ------------------
# 1) Year bar chart
# ------------------
year_counts = (
    df["year"]
    .value_counts(dropna=False)
    .sort_index()
    .rename("count")
    .to_frame()
)

plt.figure()
year_counts["count"].plot(kind="bar")
plt.title("Count of Titles by Year")
plt.xlabel("Year")
plt.ylabel("Count")
plt.tight_layout()
plt.show()

# ------------------
# Show the first 10 titles (as they appear in the file)
# ------------------
top10_all = df["Title"].head(10).reset_index(drop=True)
print("\n[Top 10 titles overall]")
for i, t in enumerate(top10_all, 1):
    print(f"{i:>2}. {t}")

# -----------------------------------------------------
# 3) Share of titles containing "她" (overview)
# -----------------------------------------------------
df["has_she_in_title"] = df["Title"].str.contains(SHE_REGEX, na=False)
share_overall = float(df["has_she_in_title"].mean())

she_by_year = (
    df.groupby("year")["has_she_in_title"]
      .mean()
      .rename("share_with_she")
      .to_frame()
)

plt.figure()
she_by_year["share_with_she"].plot(kind="bar")
plt.title("Share of Titles Containing 'She' by Year")
plt.xlabel("Year")
plt.ylabel("Share")
plt.tight_layout()
plt.show()

# ------------------
# Show the first 10 titles that contain the single character "她"
# (sorted by year, then by title for readability)
# ------------------
hits = df[df["Title"].str.contains("她", na=False)].copy()
hits = hits.sort_values(["year", "Title"], na_position="last")

# choose a few helpful columns if they exist
cols_wanted = ["Title", "year", "Newspaper Title", "Time", "SourceFile"]
cols = [c for c in cols_wanted if c in hits.columns]

print("\n[Top 10 titles containing '她']")
print(hits[cols].head(10).to_string(index=False))

# ------------------
# 4) SnowNLP sentiment
# ------------------
def snow_score(text: str) -> float:
    """
    Return SnowNLP sentiment in [0,1]; higher = more positive.
    Returns NaN for empty or non-string inputs.
    """
    if not isinstance(text, str) or not text.strip():
        return np.nan
    try:
        return float(SnowNLP(text).sentiments)
    except Exception:
        return np.nan

def label_from_posprob(p: float, band: float = NEUTRAL_BAND) -> str:
    """
    Convert a positive-probability (0..1) into a label with a neutral band.
    >= 0.5 + band -> positive; <= 0.5 - band -> negative; else neutral.
    """
    if pd.isna(p):
        return "neutral"
    if p >= 0.5 + band:
        return "positive"
    if p <= 0.5 - band:
        return "negative"
    return "neutral"

# Score ALL titles
print("[INFO] Scoring ALL titles (SnowNLP)…")
df["pos_score_all"] = [snow_score(t) for t in tqdm(df["Title"].fillna("").tolist())]
df["sent_all"] = df["pos_score_all"].apply(label_from_posprob)

# Score only titles that explicitly contain "她…"
df_she = df[df["has_she_in_title"]].copy()
print("[INFO] Scoring SHE-subset titles (SnowNLP)…")
df_she["pos_score_title_she"] = [snow_score(t) for t in tqdm(df_she["Title"].fillna("").tolist())]
df_she["sent_title_she"] = df_she["pos_score_title_she"].apply(label_from_posprob)

# ------------------
# Summaries & yearly breakdowns
# ------------------
def summarize(series: pd.Series) -> pd.Series:
    """
    Summarize counts and positive rate for a label series with values in {positive, neutral, negative}.
    """
    vc = series.value_counts()
    n   = int(vc.sum())
    pos = int(vc.get("positive", 0))
    neg = int(vc.get("negative", 0))
    neu = int(vc.get("neutral",  0))
    pos_rate = pos / n if n else np.nan
    return pd.Series({"n": n, "positive": pos, "negative": neg, "neutral": neu, "pos_rate": pos_rate})

sum_all = summarize(df["sent_all"])
sum_she = summarize(df_she["sent_title_she"])

all_by_year = df.groupby("year")["sent_all"].value_counts().unstack(fill_value=0).sort_index()
she_by_year_sent = df_she.groupby("year")["sent_title_she"].value_counts().unstack(fill_value=0).sort_index()

print("\n[ALL] Overall sentiment counts/rates:\n", sum_all)
print("\n[SHE] Sentiment for titles containing 'She':\n", sum_she)

# ------------------
# Charts: yearly sentiment distributions
# ------------------
if not all_by_year.empty:
    plt.figure()
    (all_by_year[["positive","negative","neutral"]]
     .plot(kind="bar", figsize=(12,4)))
    plt.title("All Titles: Sentiment by Year (SnowNLP)")
    plt.xlabel("Year")
    plt.ylabel("Count")
    plt.tight_layout()
    plt.show()

if not she_by_year_sent.empty:
    plt.figure()
    (she_by_year_sent[["positive","negative","neutral"]]
     .plot(kind="bar", figsize=(12,4)))
    plt.title("Titles with 'She': Sentiment by Year (SnowNLP)")
    plt.xlabel("Year")
    plt.ylabel("Count")
    plt.tight_layout()
    plt.show()